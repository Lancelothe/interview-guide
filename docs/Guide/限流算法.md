## 什么是限流

限流是对系统的**出入流量**进行**控制**，防止大流量出入，导致**资源**不足，系统不稳定。

限流系统是对资源访问的控制组件，控制主要的两个功能：**限流策略**和**熔断策略**，对于熔断策略，不同的系统有不同的熔断策略诉求，有的系统希望直接拒绝、有的系统希望排队等待、有的系统希望服务降级、有的系统会定制自己的熔断策略，这里只针对**限流策略**这个功能做详细的设计。

## 限流算法

核心的算法主要就是四种：
A 类：计数器法，滑动窗口法
B 类：令牌桶法，漏桶法

这里的四种算法通常都是在应用级别讨论的，这里不重复介绍这四种算法的实现思路了，只不过我人为的将他们分成了 A，B 两类。

- A 类算法，否决式限流。即如果系统设定限流方案是 1 分钟允许 100 次调用，那么真实请求 1 分钟调用 200 次的话，意味着超出的 100 次调用，得到的是空结果或者调用频繁异常。（**滑动窗口法是计数器法的升级，因为计数器法会存在临界值问题，不是相对的时间**）
- B 类算法，阻塞式限流。即如果系统设定限流方案是 1 分钟允许 100 次调用，那么真实请求 1 分钟调用 200 次的话，意味着超出的 100 次调用，会均匀安排到下一分钟返回。（当然 B 类算法，也可以立即返回失败，也可以达到否决式限流的效果）

[固定窗口和滑动窗口算法了解一下 \- 眯眯眼猫头鹰的小树杈 \- SegmentFault 思否](https://segmentfault.com/a/1190000016359991)

### 1、限制瞬时并发数

Guava RateLimiter 提供了令牌桶算法实现：平滑突发限流(SmoothBursty)和平滑预热限流(SmoothWarmingUp)实现。

### 2、限制某个接口的时间窗最大请求数

即一个时间窗口内的请求数，如想限制某个接口/服务每秒/每分钟/每天的请求数/调用量。如一些基础服务会被很多其他系统调用，比如商品详情页服务会调用基础商品服务调用，但是怕因为更新量比较大将基础服务打挂，这时我们要对每秒/每分钟的调用量进行限速；一种实现方式如下所示：

```
LoadingCache<Long, AtomicLong> counter =
        CacheBuilder.newBuilder()
                .expireAfterWrite(2, TimeUnit.SECONDS)
                .build(new CacheLoader<Long, AtomicLong>() {
                    @Override
                    public AtomicLong load(Long seconds) throws Exception {
                        return new AtomicLong(0);
                    }
                });
long limit = 1000;
while(true) {
    //得到当前秒
    long currentSeconds = System.currentTimeMillis() / 1000;
    if(counter.get(currentSeconds).incrementAndGet() > limit) {
        System.out.println("限流了:" + currentSeconds);
        continue;
    }
    //业务处理
}
```

使用Guava的Cache来存储计数器，过期时间设置为2秒（保证1秒内的计数器是有的），然后我们获取当前时间戳然后取秒数来作为KEY进行计数统计和限流，这种方式也是简单粗暴，刚才说的场景够用了。

### 3、基于 Redis 实现分布式限流

方案1：存储两个 key，一个用于计时，一个用于计数。请求每调用一次，计数器增加 1，若在计时器时间内计数器未超过阈值，则可以处理任务。（这个方案没太懂怎么计时的key怎么运用）

方案2：用一个key自增请求并设置过期时间

```lua
local key = "rate.limit:" .. KEYS[1] --限流KEY
local limit = tonumber(ARGV[1])       --限流大小
local time = tonumber(ARGV[2])        --限流时间窗口
local current = tonumber(redis.call('get', key) or "0")
if current + 1 > limit then --如果超出限流大小
  return 0
else
-- 请求数+1
  redis.call("INCRBY", key, "1")
  redis.call("expire", key, time)
  return current + 1
end
```

## 常用的限流算法

常用的限流算法有两种：漏桶算法和令牌桶算法

### 令牌桶算法

> 令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。

代表：**Guava RateLimiter**

![](https://image-hosting-lan.oss-cn-beijing.aliyuncs.com/java-ratelimiter-concurrent-hashmap-1.png)

最快的方式是使用 RateLimit 类，但是这仅限制在单节点，如果是分布式系统，每个节点的 QPS 是一样的，请求量到服务接口那的话就是 QPS * 节点数 了。所以这种方案在分布式的情况下不适用！

两种模式：

- SmoothBursty 平滑突发限流 （可以预消费来保证突发流量）
- SmoothWarmingUp 平滑预热限流 （冷启动时会以一个比较大的速率慢慢到平均速率；然后趋于平均速率）

### 漏桶算法

> 漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。

![](https://image-hosting-lan.oss-cn-beijing.aliyuncs.com/leaky_bucket.png)



## 分布式限流

而分布式限流常用的则有 Hystrix、resilience4j、Sentinel 等框架，但这些框架都需引入第三方的类库，对于国企等一些保守的企业，引入外部类库都需要经过层层审批，较为麻烦。

[基于redis的分布式RateLimiter\(限流\)实现 \- 林中小舍 \- SegmentFault 思否](https://segmentfault.com/a/1190000012947169)

[Java并发：分布式应用限流 Redis \+ Lua 实践 \- 搜云库技术团队 \- SegmentFault 思否](https://segmentfault.com/a/1190000016042927)

[分布式服务限流实战，已经为你排好坑了\-InfoQ](https://www.infoq.cn/article/Qg2tX8fyw5Vt-f3HH673)

## 接入层限流

接入层通常指请求流量的入口，该层的主要目的有：负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等等

对于Nginx接入层限流可以使用Nginx自带了两个模块：

- 连接数限流模块ngx_http_limit_conn_module

- 漏桶算法实现的请求限流模块ngx_http_limit_req_module。

- OpenResty提供的Lua限流模块lua-resty-limit-traffic进行更复杂的限流场景。

limit_conn用来对某个KEY对应的总的网络连接数进行限流，可以按照如IP、域名维度进行限流。

limit_req用来对某个KEY对应的请求的平均速率进行限流，并有两种用法：平滑模式（delay）和允许突发模式(nodelay)。

[谈谈高并发系统的限流 \- nick hao \- 博客园](https://www.cnblogs.com/haoxinyue/p/6792309.html)

[高并发系统限流设计 \- 简书](https://www.jianshu.com/p/d6fb865b970b)

## 相关方案

### 业务端限流：

业务端做限流的话，请求来源于上有系统，流量要求是比较平稳的，峰值不能太高，否则可能一瞬间打挂系统，令牌桶和计数器方式就不太合适了。因为如果流量直接打到业务系统我们是没法进行预估的，大概率会有突发流量，所以选择直接使用流量桶就比较合适了。

### consumer 控制对下游流量：

我所处的业务场景是nginx + lua 打入[redis](https://cloud.tencent.com/product/crs?from=10680) 则认为成功，consumer端消费消息，然后持续固定qps对下游发起请求。这种场景下，把消费速率&对下游qps控制放在consumer端来做就比较合适了。首先我们从Redis或者日志文件中读取了数据，并且拼接了请求任务放到任务队列中。然后线程池从任务队列中取任务发起请求，首先我们需要控制加入任务队列的速率，因为加入的任务队列的速度大于任务队列的消费速度，肯定是会导致OOM产生的，

我这里使用的是类似令牌桶的方式，一个线程取n个任务，然后线程内串行，几个线程并行，这样就一定程度上保证了不会出现令牌桶的流量不均问题了，同时减少了锁的争用。实际上使用漏斗算法也是合适的，但是对于这个场景来说，溢出任务实际上是不太好控制，需要让请求的加入速率与消费速度相对保持一致，这一点控制不好很容易oom的，所以直接采用任务队列 + 令牌桶实现是最方便控制也是最容易实现的，采用线程内一次取多个，串行发起请求的方式是可以一定程度上控制住流量的 实践证明效果不错。

[高并发下的限流策略 \- 云\+社区 \- 腾讯云](https://cloud.tencent.com/developer/article/1477216)

参考

[Guava RateLimiter源码解析以及分布式限流总结\_maoyeqiu的专栏\-CSDN博客](https://blog.csdn.net/maoyeqiu/article/details/97493765)

[基于Redis的限流系统的设计 \- 作业部落 Cmd Markdown 编辑阅读器](https://www.zybuluo.com/kay2/note/949160)

[RateLimiter配合ConcurrentHashMap对用户进行简单限流 \- 沉默王二博客](http://www.itwanger.com/java/2019/12/09/java-ratelimiter-concurrent-hashmap.html)

[基于分布式环境下限流系统的设计 \| zhisheng的博客](http://www.54tianzhisheng.cn/2017/11/18/flow-control/)

[分布式环境下限流方案的实现redis RateLimiter Guava,Token Bucket, Leaky Bucket \- 沧海一滴 \- 博客园](https://www.cnblogs.com/softidea/p/6229543.html)

[Guava RateLimiter限流 \- 掘金](https://juejin.im/post/5c7510f3518825625e4ae41b)

[基于Redis和Lua的分布式限流 \- 知乎](https://zhuanlan.zhihu.com/p/61661082)