## elastic-job-lite原理

举个典型的job场景，比如余额宝里的昨日收益，系统需要job在每天某个时间点开始，给所有余额宝用户计算收益。如果用户数量不多，我们可以轻易使用quartz来完成，我们让计息job在某个时间点开始执行，循环遍历所有用户计算利息，这没问题。可是，如果用户体量特别大，我们可能会面临着在第二天之前处理不完这么多用户。另外，我们部署job的时候也得注意，我们可能会把job直接放在我们的webapp里，webapp通常是多节点部署的，这样，我们的job也就是多节点，多个job同时执行，很容易造成重复执行，比如用户重复计息，为了避免这种情况，我们可能会对job的执行加锁，保证始终只有一个节点能执行，或者干脆让job从webapp里剥离出来，独自部署一个节点。

**elastic-job就可以帮助我们解决上面的问题，elastic底层的任务调度还是使用的quartz，通过zookeeper来动态给job节点分片。**

我们来看：
**很大体量的用户需要在特定的时间段内计息完成**      

我们肯定是希望我们的任务可以通过集群达到水平扩展，集群里的每个节点都处理部分用户，不管用户数量有多庞大，我们只要增加机器就可以了，比如单台机器特定时间能处理n个用户，2台机器处理2n个用户，3台3n，4台4n...，再多的用户也不怕了。
使用elastic-job开发的作业都是zookeeper的客户端，比如我希望3台机器跑job，我们将任务分成3片，框架通过zk的协调，最终会让3台机器分别分配到0,1,2的任务片，比如server0-->0，server1-->1，server2-->2，当server0执行时，可以只查询id%3\==0的用户，server1执行时，只查询id%3\==1的用户，server2执行时，只查询id%3==2的用户。

**任务部署多节点引发重复执行**  
在上面的基础上，我们再增加server3，此时，server3分不到任务分片，因为只有3片，已经分完了。没有分到任务分片的作业程序将不执行。
如果此时server2挂了，那么server2的分片项会分配给server3，server3有了分片，就会替代server2执行。
如果此时server3也挂了，只剩下server0和server1了，框架也会自动把server3的分片随机分配给server0或者server1，可能会这样，server0-->0，server1-->1,2。
这种特性称之为弹性扩容，即elastic-job名称的由来。

 

[elastic\-job的原理简介和使用 \- 我和我的倔强 \- 博客园](https://www.cnblogs.com/takemybreathaway/articles/10174952.html)

1. Elastic-Job-Lite框架的任务处理、执行等都是针对的分片项，也就是说框架面向的是定时任务的分片项，而不是定时任务本身。如果我们不打算对定时任务分片，那么可以把分片数设为1，这样在sharding节点下创建1个分片项0，0分片项将会被分配给一个instance，并启动执行。

2. Elastic-Job-Lite是提供失效转移功能的，即当正在执行的任务项遇到进程退出或机器宕机等故障，该任务项应该转移到某空闲服务器执行。但是，该功能存在bug：（1）失效转移只能在同一机器上不同实例间完成，跨机器无效；（2）没有判断机器宕机时任务项是否正在执行状态，而是只要遇到宕机，即使任务项没有开始执行，也被转移到其他机器上执行一遍，导致重复执行。

3. Elastic-Job-Lite是预分片，不是动态分片，即Elastic-Job-Lite是在服务启动时就完成分片项的创建和分配，并保存在zk节点上，而不是定时任务在每次启动时，根据机器的处理能力，重新分配任务项，例如：任务比较繁忙的机器不参与新一轮的任务项分配。这样做的目的是对zk弱依赖，如果进行真正的动态分片，对于秒级的定时任务将会产生很大影响，因为每次任务启动，应用服务器都要跟zookeeper进行通信，并执行重新分片的逻辑，频繁的通信，对于秒级定时任务，会错过很多次执行

[分布式定时任务调度平台Elastic\-Job技术详解\_慕课手记](https://www.imooc.com/article/details/id/31907)



## 失效转移

所谓失效转移，就是在执行任务的过程中遇见异常的情况，这个分片任务可以在其他节点再次执行。这个和上面的HA不同，对于HA，上面如果任务终止，那么不会在其他任务实例上再次重新执行。

Job的失效转移监听来源于FailoverListenerManager中JobCrashedJobListener的dataChanged方法。FailoverListenerManager监听的是zk的instance节点删除事件。如果任务配置了failover等于true，其中某个instance与zk失去联系或被删除，并且失效的节点又不是本身，就会触发失效转移逻辑。

首先，在某个任务实例失效时，elastic-job会在leader节点下面创建failover节点以及items节点。items节点下会有失效任务实例的原本应该做的分片好。比如，失效的任务实例原来负责分片1和2。那么items节点下就会有名字叫1的子节点，就代表分片1需要转移到其他节点上去运行。

然后，由于每个存活着的任务实例都会收到zk节点丢失的事件，哪个分片失效也已经在leader节点的failover子节点下。所以这些或者的任务实例就会争抢这个分片任务来执行。为了保证不重复执行，elastic-job使用了curator的LeaderLatch类来进行选举执行。在获得执行权后，就会在sharding节点的分片上添加failover节点，并写上任务实例，表示这个故障任务迁移到某一个任务实例上去完成。

执行完成后，会把相应的节点和数据删除，避免下一次重复执行。



 \>>elastic-job使用了quartz的调度机制，内部原理一致，增加了性能和可用性。

 \>>elastic-job使用注册中心(zookeeper)替换了quartz的jdbc数据存储方式，性能有较大提升。

 \>> elastic-job增加了job的追踪(使用Listener)，便于monitor

 \>>elastic-job使用了分片机制，可以将job分成多个任务项，放到不同的地方执行

 \>>elastic-job仅支持cronTrigger，quartz支持更多的trigger实现